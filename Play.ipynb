{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhanwenchen/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from lib.aperture_dataset import ApertureDataset\n",
    "from lib.lenet import LeNet\n",
    "from lib.fit import fit\n",
    "\n",
    "log_fname = 'results_%s.csv' % time.strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "k = 4\n",
    "fname_train = 'training_data/training_data.h5'\n",
    "fname_validate = 'training_data/validation_data.h5'\n",
    "save_path = 'save_here'\n",
    "\n",
    "# model_params_dict = {\n",
    "#     'input_dim': 130, # TODO: move?\n",
    "#     'output_dim': 130,\n",
    "#     'layer_width': 260,\n",
    "#     'num_hidden_layers': 4,\n",
    "# }\n",
    "\n",
    "model_params_dict = {\n",
    "    'input_dim': 65, # TODO: move?\n",
    "    'output_dim': 130,\n",
    "    'layer_width': 260,\n",
    "    'num_hidden_layers': 4,\n",
    "}\n",
    "\n",
    "input_dim = model_params_dict['input_dim']\n",
    "output_dim = model_params_dict['output_dim']\n",
    "\n",
    "num_samples = 10 ** 5\n",
    "dat_train = ApertureDataset(fname_train, num_samples, k)\n",
    "\n",
    "\n",
    "num_samples = 10 ** 4\n",
    "dat_train2 = ApertureDataset(fname_train, num_samples, k)\n",
    "\n",
    "num_samples = 10 ** 4\n",
    "dat_validate = ApertureDataset(fname_validate, num_samples, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| run | cost       | diff   | kernel_size | num_kernels | num_hidden_layers | hidden_size | batch_size |\n",
      "| --- | ---------- | ------ | ----------- | ----------- | ----------------- | ----------- | ---------- |\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6063fd7606b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0musing_cuda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                         \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%03d, %0.5f, %2.3f%%, %02d, %02d, %d, %03d, %03d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrun_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_kernels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/beam/beam_nn/lib/fit.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, loader, train2_loader, validate_loader, optimizer, save_path, cuda, loss)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss_train_epoch_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mloss_valid_epoch_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mdiff_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_valid\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloss_valid_best\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mloss_valid_best\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mtime_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtime_epoch_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "momentum = 0\n",
    "# TODO: switch up learning rates\n",
    "\n",
    "using_cuda = False\n",
    "\n",
    "try_batch_sizes = [32, 64, 128]\n",
    "try_hidden_sizes = range(10, 720, 10)\n",
    "try_num_hidden_layers = range(1, 7)\n",
    "try_kernel_sizes = range(2, 10)\n",
    "try_num_kernels = [1]\n",
    "\n",
    "run_index = 0\n",
    "with open(log_fname, 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    header = 'index, cost, diff, kernel_size, num_kernels, num_hidden_layers, hidden_size, batch_size'\n",
    "    \n",
    "    print(\"| run | cost       | diff   | kernel_size | num_kernels | num_hidden_layers | hidden_size | batch_size |\")\n",
    "    print(\"| --- | ---------- | ------ | ----------- | ----------- | ----------------- | ----------- | ---------- |\")\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for batch_size in try_batch_sizes:\n",
    "        \n",
    "        train_loader = DataLoader(dat_train, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "        train_loader2 = DataLoader(dat_train2, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "        validate_loader = DataLoader(dat_validate, batch_size=batch_size, shuffle=False, num_workers=1)        \n",
    "    \n",
    "        for kernel_size in try_kernel_sizes:\n",
    "            # TODO: in lenet.py, change fc layer input_size to allow any num_kernels\n",
    "            for num_kernels in try_num_kernels:\n",
    "\n",
    "                for num_hidden_layers in try_num_hidden_layers:\n",
    "\n",
    "                    for hidden_size in try_hidden_sizes:\n",
    "                    \n",
    "                        model = LeNet(input_dim, output_dim, hidden_size, num_hidden_layers, batch_size)\n",
    "                        optimizer = optim.SGD(model.parameters(), lr, momentum)\n",
    "                        if using_cuda: model.cuda()\n",
    "                        cost, diff = fit(model, train_loader, train_loader2, validate_loader, optimizer, save_path, cuda=using_cuda)\n",
    "        \n",
    "                        row = '%03d, %0.5f, %2.3f%%, %02d, %02d, %d, %03d, %03d' % (run_index, cost, diff, kernel_size, num_kernels, num_hidden_layers, hidden_size, batch_size)\n",
    "                        \n",
    "                        print(\"| %03d | %0.5f    | %2.3f%% | %02d          | %02d          | %d                 | %03d         | %03d        |\" % (run_index, cost, diff, kernel_size, num_kernels, num_hidden_layers, hidden_size, batch_size))\n",
    "                        writer.writerow(row)\n",
    "                    \n",
    "                        run_index += 1\n",
    "    \n",
    "\n",
    "print(\"\\nIt's all over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
